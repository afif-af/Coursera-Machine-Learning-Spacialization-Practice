{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/afifaf20/courserasupervisedweek3lab1?scriptVersionId=198316861\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\n%matplotlib widget\nimport matplotlib.pyplot as plt\nfrom lab_utils_common import dlc, plot_data\nfrom plt_one_addpt_onclick import plt_one_addpt_onclick\nplt.style.use('./deeplearning.mplstyle')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T04:20:53.042446Z","iopub.execute_input":"2024-09-26T04:20:53.04289Z","iopub.status.idle":"2024-09-26T04:20:53.564707Z","shell.execute_reply.started":"2024-09-26T04:20:53.042846Z","shell.execute_reply":"2024-09-26T04:20:53.563077Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlab_utils_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dlc, plot_data\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplt_one_addpt_onclick\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plt_one_addpt_onclick\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./deeplearning.mplstyle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lab_utils_common'"],"ename":"ModuleNotFoundError","evalue":"No module named 'lab_utils_common'","output_type":"error"}]},{"cell_type":"markdown","source":"## Classification Problems\n<img align=\"left\" src=\"./images/C1_W3_Classification.png\"     style=\" width:380px; padding: 10px; \" > Examples of classification problems are things like: identifying email as Spam or Not Spam or determining if a tumor is malignant or benign. In particular, these are examples of *binary* classification where there are two possible outcomes.  Outcomes can be  described in pairs of 'positive'/'negative' such as 'yes'/'no, 'true'/'false' or '1'/'0'. \n\nPlots of classification data sets often use symbols to indicate the outcome of an example. In the plots below, 'X' is used to represent the positive values while 'O' represents negative outcomes.","metadata":{}},{"cell_type":"code","source":"x_train = np.array([0., 1, 2, 3, 4, 5])\ny_train = np.array([0,  0, 0, 1, 1, 1])\nX_train2 = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\ny_train2 = np.array([0, 0, 0, 1, 1, 1])","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pos = y_train == 1\nneg = y_train == 0\n\nfig,ax = plt.subplots(1,2,figsize=(8,3))\n#plot 1, single variable\nax[0].scatter(x_train[pos], y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\nax[0].scatter(x_train[neg], y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n              edgecolors=dlc[\"dlblue\"],lw=3)\n\nax[0].set_ylim(-0.08,1.1)\nax[0].set_ylabel('y', fontsize=12)\nax[0].set_xlabel('x', fontsize=12)\nax[0].set_title('one variable plot')\nax[0].legend()\n\n#plot 2, two variables\nplot_data(X_train2, y_train2, ax[1])\nax[1].axis([0, 4, 0, 4])\nax[1].set_ylabel('$x_1$', fontsize=12)\nax[1].set_xlabel('$x_0$', fontsize=12)\nax[1].set_title('two variable plot')\nax[1].legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T04:22:34.165763Z","iopub.execute_input":"2024-09-26T04:22:34.166226Z","iopub.status.idle":"2024-09-26T04:22:34.341853Z","shell.execute_reply.started":"2024-09-26T04:22:34.166181Z","shell.execute_reply":"2024-09-26T04:22:34.340386Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Canvas(toolbar=None)","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6536c5a8734425963e52199e6dc32e"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#plot 1, single variable\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscatter(x_train[pos], y_train[pos], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my=1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscatter(x_train[neg], y_train[neg], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my=0\u001b[39m\u001b[38;5;124m\"\u001b[39m, facecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m----> 8\u001b[0m               edgecolors\u001b[38;5;241m=\u001b[39m\u001b[43mdlc\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlblue\u001b[39m\u001b[38;5;124m\"\u001b[39m],lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     10\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.08\u001b[39m,\u001b[38;5;241m1.1\u001b[39m)\n\u001b[1;32m     11\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'dlc' is not defined"],"ename":"NameError","evalue":"name 'dlc' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"Note in the plots above:\n- In the single variable plot, positive results are shown both a red 'X's and as y=1. Negative results are blue 'O's and are located at y=0.\n   - Recall in the case of linear regression, y would not have been limited to two values but could have been any value.\n- In the two-variable plot, the y axis is not available.  Positive results are shown as red 'X's, while negative results use the blue 'O' symbol.\n    - Recall in the case of linear regression with multiple variables, y would not have been limited to two values and a similar plot would have been three-dimensional.","metadata":{}},{"cell_type":"markdown","source":"## Linear Regression approach\nIn the previous week, you applied linear regression to build a prediction model. Let's try that approach here using the simple example that was described in the lecture. The model will predict if a tumor is benign or malignant based on tumor size.  Try the following:\n- Click on 'Run Linear Regression' to find the best linear regression model for the given data.\n    - Note the resulting linear model does **not** match the data well. \nOne option to improve the results is to apply a *threshold*. \n- Tick the box on the 'Toggle 0.5 threshold' to show the predictions if a threshold is applied.\n    - These predictions look good, the predictions match the data\n- *Important*: Now, add further 'malignant' data points on the far right, in the large tumor size range (near 10), and re-run linear regression.\n    - Now, the model predicts the larger tumor, but data point at x=3 is being incorrectly predicted!\n- to clear/renew the plot, rerun the cell containing the plot command.","metadata":{}},{"cell_type":"code","source":"w_in = np.zeros((1))\nb_in = 0\nplt.close('all') \naddpt = plt_one_addpt_onclick( x_train,y_train, w_in, b_in, logistic=False)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m b_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m addpt \u001b[38;5;241m=\u001b[39m \u001b[43mplt_one_addpt_onclick\u001b[49m( x_train,y_train, w_in, b_in, logistic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'plt_one_addpt_onclick' is not defined"],"ename":"NameError","evalue":"name 'plt_one_addpt_onclick' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"The example above demonstrates that the linear model is insufficient to model categorical data. The model can be extended as described in the following lab.","metadata":{}}]}